#!/usr/bin/env python3
"""
ComBaseä¸»çˆ¬è™« - æ¯1000æ¡è®°å½•ä¸€ä¸ªæ–‡ä»¶
ä¼˜åŒ–ç‰ˆæœ¬ï¼Œè§£å†³æ‰€æœ‰å·²çŸ¥é—®é¢˜
"""

import os
import time
import json
import csv
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass
import re

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

@dataclass
class TimeSeriesData:
    """æ—¶é—´åºåˆ—æ•°æ®"""
    time_hours: List[float]
    values: List[float]

@dataclass
class CompleteComBaseRecord:
    """å®Œæ•´çš„ComBaseè®°å½•æ•°æ®ç»“æ„"""
    record_id: str
    organism: str
    food: str
    temperature: str
    aw: str
    ph: str
    page_number: int
    logc_series: Optional[TimeSeriesData] = None
    
    def to_flat_dict(self) -> Dict:
        """è½¬æ¢ä¸ºæ‰å¹³å­—å…¸ï¼Œç”¨äºCSVè¾“å‡º"""
        flat_data = {
            'record_id': self.record_id,
            'organism': self.organism,
            'food': self.food,
            'temperature': self.temperature,
            'aw': self.aw,
            'ph': self.ph,
            'page_number': self.page_number
        }
        
        if self.logc_series:
            flat_data['logc_points'] = len(self.logc_series.time_hours)
            flat_data['logc_duration'] = max(self.logc_series.time_hours) if self.logc_series.time_hours else 0
            flat_data['logc_initial'] = self.logc_series.values[0] if self.logc_series.values else None
            flat_data['logc_final'] = self.logc_series.values[-1] if self.logc_series.values else None
            flat_data['logc_series_json'] = json.dumps(list(zip(self.logc_series.time_hours, self.logc_series.values)))
        else:
            flat_data['logc_points'] = 0
            flat_data['logc_duration'] = 0
            flat_data['logc_initial'] = None
            flat_data['logc_final'] = None
            flat_data['logc_series_json'] = None
        
        return flat_data

class ComBaseMainScraper:
    """ComBaseä¸»çˆ¬è™« - æ¯1000æ¡è®°å½•ä¸€ä¸ªæ–‡ä»¶"""
    
    def __init__(self, output_dir: str = "data/segments", records_per_file: int = 1000):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.records_per_file = records_per_file
        self.driver = None
        self.wait = None
        
        # è¿›åº¦æ–‡ä»¶
        self.progress_file = Path("data/scraping_progress.json")
        self.progress = self.load_progress()
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # ComBaseé…ç½®
        self.login_url = "https://combasebrowser.errc.ars.usda.gov/membership/Login.aspx"
        self.search_url = "https://combasebrowser.errc.ars.usda.gov/SearchResults.aspx"
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_pages = 6075
        self.current_file_number = 0
        self.current_records = []
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / f"main_scraper_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def load_progress(self) -> Dict:
        """åŠ è½½è¿›åº¦"""
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r') as f:
                    return json.load(f)
            except Exception:
                pass
        
        return {
            "start_time": datetime.now().isoformat(),
            "current_page": 1,
            "completed_files": [],
            "total_records": 0,
            "last_file": 0,
            "status": "ready"
        }
    
    def save_progress(self):
        """ä¿å­˜è¿›åº¦"""
        self.progress["last_update"] = datetime.now().isoformat()
        with open(self.progress_file, 'w') as f:
            json.dump(self.progress, f, indent=2)
    
    def setup_driver(self):
        """è®¾ç½®Chromeæµè§ˆå™¨"""
        chrome_options = Options()
        chrome_options.add_argument("--window-size=1400,1000")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        self.wait = WebDriverWait(self.driver, 30)
        
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        self.logger.info("æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")
        
    def login(self, username: str, password: str) -> bool:
        """ç™»å½•ComBaseç³»ç»Ÿ"""
        try:
            self.logger.info("å¼€å§‹ç™»å½•")
            self.driver.get(self.login_url)
            time.sleep(3)
            
            username_input = self.wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "input[name='Login1$UserName']"))
            )
            username_input.clear()
            username_input.send_keys(username)
            
            password_input = self.driver.find_element(By.CSS_SELECTOR, "input[name='Login1$Password']")
            password_input.clear()
            password_input.send_keys(password)
            
            login_button = self.driver.find_element(By.CSS_SELECTOR, "input[name='Login1$Button1']")
            login_button.click()
            time.sleep(5)
            
            if "Login.aspx" not in self.driver.current_url:
                self.logger.info("ç™»å½•æˆåŠŸ")
                return True
            else:
                self.logger.error("ç™»å½•å¤±è´¥")
                return False
                
        except Exception as e:
            self.logger.error(f"ç™»å½•å‡ºé”™: {e}")
            return False
            
    def navigate_to_search_results(self) -> bool:
        """å¯¼èˆªåˆ°æœç´¢ç»“æœé¡µé¢"""
        try:
            self.logger.info("å¯¼èˆªåˆ°æœç´¢ç»“æœé¡µé¢")
            self.driver.get(self.search_url)
            time.sleep(5)
            
            if "SearchResults.aspx" in self.driver.current_url:
                self.logger.info("æœç´¢ç»“æœé¡µé¢åŠ è½½æˆåŠŸ")
                return True
            else:
                self.logger.error("æœç´¢ç»“æœé¡µé¢åŠ è½½å¤±è´¥")
                return False
                
        except Exception as e:
            self.logger.error(f"å¯¼èˆªå¤±è´¥: {e}")
            return False
    
    def go_to_next_page(self) -> bool:
        """è·³è½¬åˆ°ä¸‹ä¸€é¡µ"""
        try:
            next_link = self.driver.find_element(By.XPATH, "//div[@class='cbpagination']//a[@data-action='next']")
            if next_link and 'disabled' not in next_link.get_attribute('class'):
                next_link.click()
                time.sleep(1.5)
                
                try:
                    self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "input.exportchk")))
                    return True
                except:
                    return False
            return False
        except Exception as e:
            self.logger.debug(f"ä¸‹ä¸€é¡µè·³è½¬å¤±è´¥: {e}")
            return False
    
    def parse_time_series(self, value_string: str) -> Optional[TimeSeriesData]:
        """è§£ææ—¶é—´åºåˆ—æ•°æ®"""
        try:
            if not value_string or value_string.strip() == "":
                return None
                
            pattern = r'\[([0-9.]+),([0-9.]+)\]'
            matches = re.findall(pattern, value_string)
            
            if not matches:
                return None
                
            time_hours = []
            values = []
            
            for time_str, value_str in matches:
                time_hours.append(float(time_str))
                values.append(float(value_str))
                
            return TimeSeriesData(time_hours=time_hours, values=values)
            
        except Exception as e:
            self.logger.debug(f"è§£ææ—¶é—´åºåˆ—å¤±è´¥: {e}")
            return None
    
    def parse_page_data(self, page_number: int) -> List[CompleteComBaseRecord]:
        """è§£æå½“å‰é¡µé¢çš„æ•°æ®"""
        try:
            time.sleep(1)
            
            html = self.driver.page_source
            soup = BeautifulSoup(html, 'html.parser')
            
            records = []
            checkboxes = soup.find_all('input', {'data-recordid': True, 'class': 'exportchk'})
            
            for i, checkbox in enumerate(checkboxes):
                try:
                    record_id = checkbox.get('data-recordid')
                    record_container = checkbox.find_parent('div', class_='col-lg-9')
                    
                    if not record_container:
                        continue
                    
                    # æå–åŸºç¡€æ•°æ®
                    organism = ""
                    food = ""
                    temperature = ""
                    aw = ""
                    ph = ""

                    # è·å–è®°å½•ç¼–å·
                    record_number = ""
                    record_nb_span = record_container.find('span', id=lambda x: x and 'lblRecordNb' in x)
                    if record_nb_span:
                        record_number = record_nb_span.get_text(strip=True)

                    # è·å–organismå’Œfoodä¿¡æ¯
                    record_titles = record_container.find_all('span', class_='recordTitle')
                    organism_part = ""
                    food_part = ""

                    if len(record_titles) >= 2:
                        organism_part = record_titles[0].get_text(strip=True)  # Aerobic total spoilage bacteria
                        food_part = record_titles[2].get_text(strip=True) if len(record_titles) > 2 else ""  # in precooked beef

                    # æ„å»ºå®Œæ•´çš„organismåç§°ï¼šç¼–å· + organism + food
                    if record_number and organism_part:
                        if food_part:
                            organism = f"{record_number} {organism_part} {food_part}"
                        else:
                            organism = f"{record_number} {organism_part}"
                    else:
                        organism = organism_part

                    # foodå­—æ®µä¿æŒåŸæ¥çš„é€»è¾‘ï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰
                    food = food_part
                    
                    temp_span = record_container.find('span', id='lblTemp')
                    if temp_span:
                        temperature = temp_span.get_text(strip=True)
                    
                    aw_span = record_container.find('span', id='lblAw')
                    if aw_span:
                        aw = aw_span.get_text(strip=True)
                    
                    ph_span = record_container.find('span', id='lblPh')
                    if ph_span:
                        ph = ph_span.get_text(strip=True)
                    
                    # æå–æ—¶é—´åºåˆ—æ•°æ®
                    logc_series = None
                    hidden_logcs = soup.find('input', {'id': f'ContentPlaceHolder1_CBListView_HiddenLogcs_{i}'})
                    if hidden_logcs:
                        logc_value = hidden_logcs.get('value', '')
                        logc_series = self.parse_time_series(logc_value)
                    
                    record = CompleteComBaseRecord(
                        record_id=record_id,
                        organism=organism,
                        food=food,
                        temperature=temperature,
                        aw=aw,
                        ph=ph,
                        page_number=page_number,
                        logc_series=logc_series
                    )
                    
                    records.append(record)
                    
                except Exception as e:
                    self.logger.debug(f"è§£æè®°å½•å¤±è´¥: {e}")
                    continue
            
            return records

        except Exception as e:
            self.logger.error(f"è§£æç¬¬ {page_number} é¡µå¤±è´¥: {e}")
            return []

    def save_records_file(self, file_number: int):
        """ä¿å­˜è®°å½•æ–‡ä»¶"""
        if not self.current_records:
            return False

        filename = f"combase_records_{file_number:04d}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        csv_file = self.output_dir / filename

        try:
            with open(csv_file, 'w', newline='', encoding='utf-8') as f:
                if self.current_records:
                    fieldnames = list(self.current_records[0].to_flat_dict().keys())
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    for record in self.current_records:
                        writer.writerow(record.to_flat_dict())

            print(f"âœ… æ–‡ä»¶ {file_number} å·²ä¿å­˜: {filename} ({len(self.current_records)} æ¡è®°å½•)")

            # æ›´æ–°è¿›åº¦
            start_page = self.progress['current_page'] - len(self.current_records)//10 + 1
            end_page = self.progress['current_page']

            self.progress["completed_files"].append({
                "file_number": file_number,
                "filename": filename,
                "records": len(self.current_records),
                "pages": f"{start_page}-{end_page}"
            })
            self.progress["total_records"] += len(self.current_records)
            self.progress["last_file"] = file_number

            # æ¸…ç©ºå½“å‰è®°å½•
            self.current_records = []
            return True

        except Exception as e:
            print(f"âŒ æ–‡ä»¶ {file_number} ä¿å­˜å‡ºé”™: {e}")
            return False

    def run_main_scraping(self, username: str, password: str, start_page: int = None):
        """è¿è¡Œä¸»çˆ¬å–"""
        print("ğŸš€ ComBaseä¸»çˆ¬è™«å¯åŠ¨")
        print("=" * 60)
        print("ğŸ’¡ ç‰¹æ€§:")
        print(f"  - æ¯ {self.records_per_file} æ¡è®°å½•ä¿å­˜ä¸€ä¸ªæ–‡ä»¶")
        print("  - è¿ç»­çˆ¬å–ï¼Œæ— éœ€é‡æ–°è·³è½¬")
        print("  - æ”¯æŒCtrl+Cå®‰å…¨ä¸­æ–­")
        print("=" * 60)

        # ç¡®å®šèµ·å§‹é¡µé¢
        if start_page is None:
            start_page = self.progress.get("current_page", 1)

        print(f"ğŸ“‹ ä»ç¬¬ {start_page} é¡µå¼€å§‹çˆ¬å–")
        print(f"ğŸ¯ ç›®æ ‡: ç¬¬ {start_page} é¡µåˆ°ç¬¬ {self.total_pages} é¡µ")
        print(f"ğŸ“¦ æ¯ä¸ªæ–‡ä»¶: {self.records_per_file} æ¡è®°å½•")

        start_time = datetime.now()
        self.progress["status"] = "running"
        self.progress["current_page"] = start_page

        try:
            self.setup_driver()

            if not self.login(username, password):
                return

            if not self.navigate_to_search_results():
                return

            # å¦‚æœä¸æ˜¯ä»ç¬¬1é¡µå¼€å§‹ï¼Œéœ€è¦è·³è½¬
            if start_page > 1:
                print(f"ğŸ”„ è·³è½¬åˆ°ç¬¬ {start_page} é¡µ...")
                for i in range(1, start_page):
                    if not self.go_to_next_page():
                        print(f"âŒ è·³è½¬å¤±è´¥ï¼Œåœåœ¨ç¬¬ {i} é¡µ")
                        return
                    if i % 50 == 0:
                        print(f"  å·²è·³è½¬åˆ°ç¬¬ {i} é¡µ...")
                print(f"âœ… æˆåŠŸè·³è½¬åˆ°ç¬¬ {start_page} é¡µ")

            # å¼€å§‹è¿ç»­çˆ¬å–
            current_page = start_page
            while current_page <= self.total_pages:
                try:
                    # è§£æå½“å‰é¡µé¢
                    page_records = self.parse_page_data(current_page)

                    if page_records:
                        self.current_records.extend(page_records)
                        print(f"âœ“ ç¬¬ {current_page} é¡µ: {len(page_records)} æ¡è®°å½• (æ€»è®¡: {len(self.current_records)})")
                    else:
                        print(f"âœ— ç¬¬ {current_page} é¡µ: è§£æå¤±è´¥")

                    # æ›´æ–°å½“å‰é¡µé¢
                    self.progress["current_page"] = current_page

                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ–‡ä»¶
                    if len(self.current_records) >= self.records_per_file:
                        self.current_file_number += 1
                        self.save_records_file(self.current_file_number)
                        self.save_progress()

                    # æ˜¾ç¤ºè¿›åº¦
                    if current_page % 50 == 0:
                        elapsed = (datetime.now() - start_time).total_seconds()
                        pages_processed = current_page - start_page + 1
                        avg_time_per_page = elapsed / pages_processed
                        remaining_pages = self.total_pages - current_page
                        estimated_remaining_time = remaining_pages * avg_time_per_page

                        print(f"\nğŸ“Š è¿›åº¦æŠ¥å‘Š (ç¬¬ {current_page} é¡µ):")
                        print(f"æ€»è¿›åº¦: {current_page}/{self.total_pages} é¡µ ({current_page/self.total_pages*100:.1f}%)")
                        print(f"å½“å‰ç¼“å­˜: {len(self.current_records)} æ¡è®°å½•")
                        print(f"å·²ä¿å­˜æ–‡ä»¶: {len(self.progress['completed_files'])} ä¸ª")
                        print(f"æ€»è®°å½•: {self.progress['total_records'] + len(self.current_records)} æ¡")
                        print(f"å¹³å‡é€Ÿåº¦: {avg_time_per_page:.1f} ç§’/é¡µ")
                        print(f"é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining_time/3600:.1f} å°æ—¶")
                        print("-" * 50)

                    # è·³è½¬åˆ°ä¸‹ä¸€é¡µ
                    if current_page < self.total_pages:
                        if not self.go_to_next_page():
                            print(f"âŒ ç¬¬ {current_page} é¡µåæ— æ³•ç»§ç»­ç¿»é¡µ")
                            break

                    current_page += 1

                except Exception as e:
                    print(f"âŒ å¤„ç†ç¬¬ {current_page} é¡µå¤±è´¥: {e}")
                    current_page += 1
                    continue

            # ä¿å­˜æœ€åä¸€æ‰¹æ•°æ®
            if self.current_records:
                self.current_file_number += 1
                self.save_records_file(self.current_file_number)

            # æ›´æ–°æœ€ç»ˆçŠ¶æ€
            if current_page > self.total_pages:
                self.progress["status"] = "completed"
                print("ğŸ‰ æ‰€æœ‰é¡µé¢çˆ¬å–å®Œæˆï¼")
            else:
                self.progress["status"] = "paused"
                print(f"â¸ï¸ çˆ¬å–æš‚åœåœ¨ç¬¬ {current_page} é¡µ")

        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜å½“å‰è¿›åº¦...")
            if self.current_records:
                self.current_file_number += 1
                self.save_records_file(self.current_file_number)
            self.progress["status"] = "paused"
        except Exception as e:
            print(f"\nâŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            self.progress["status"] = "error"
        finally:
            # ä¿å­˜æœ€ç»ˆè¿›åº¦
            self.save_progress()

            if self.driver:
                self.driver.quit()

        # æœ€ç»ˆç»Ÿè®¡
        total_time = (datetime.now() - start_time).total_seconds()
        print(f"\n" + "=" * 60)
        print("ğŸ“Š çˆ¬å–å®Œæˆç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»è€—æ—¶: {total_time/3600:.1f} å°æ—¶")
        print(f"å¤„ç†é¡µé¢: {current_page - start_page}")
        print(f"ä¿å­˜æ–‡ä»¶: {len(self.progress['completed_files'])} ä¸ª")
        print(f"æ€»è®°å½•æ•°: {self.progress['total_records']}")
        print(f"æœ€ç»ˆçŠ¶æ€: {self.progress['status']}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ComBaseä¸»çˆ¬è™«")
    print("æ¯1000æ¡è®°å½•ä¸€ä¸ªæ–‡ä»¶")
    print("=" * 60)

    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰è¿›åº¦æ–‡ä»¶
        progress_file = Path("data/scraping_progress.json")
        start_page = None

        if progress_file.exists():
            with open(progress_file, 'r') as f:
                progress = json.load(f)

            print(f"ğŸ“‹ å‘ç°è¿›åº¦æ–‡ä»¶:")
            print(f"å½“å‰é¡µé¢: {progress.get('current_page', 1)}")
            print(f"å·²ä¿å­˜æ–‡ä»¶: {len(progress.get('completed_files', []))}")
            print(f"æ€»è®°å½•æ•°: {progress.get('total_records', 0)}")
            print(f"çŠ¶æ€: {progress.get('status', 'unknown')}")

            if progress.get('status') in ['paused', 'running']:
                resume = input("\næ˜¯å¦ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­? (y/n): ").strip().lower()
                if resume == 'y':
                    start_page = progress.get('current_page', 1)
                else:
                    # æ¸…ç†è¿›åº¦æ–‡ä»¶é‡æ–°å¼€å§‹
                    progress_file.unlink()
                    print("ğŸ—‘ï¸ å·²æ¸…ç†è¿›åº¦æ–‡ä»¶ï¼Œå°†é‡æ–°å¼€å§‹")

        username = input("ComBaseç”¨æˆ·å: ").strip()
        password = input("ComBaseå¯†ç : ").strip()

        if not username or not password:
            print("âŒ ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º")
            return

        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        scraper = ComBaseMainScraper(records_per_file=1000)

        # å¼€å§‹çˆ¬å–
        scraper.run_main_scraping(username, password, start_page)

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºå‡ºé”™: {e}")


if __name__ == "__main__":
    main()
